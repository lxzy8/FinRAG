{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12314173,"sourceType":"datasetVersion","datasetId":7761896}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Install Dependencies\n\n# Install the core LangChain libraries\n!pip install langchain langchain-community langchain-chroma pypdf requests ollama\n\n# For checking GPU status\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T13:28:06.070510Z","iopub.execute_input":"2025-06-29T13:28:06.071070Z","iopub.status.idle":"2025-06-29T13:28:43.829970Z","shell.execute_reply.started":"2025-06-29T13:28:06.071046Z","shell.execute_reply":"2025-06-29T13:28:43.829063Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\nCollecting langchain-community\n  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\nCollecting langchain-chroma\n  Downloading langchain_chroma-0.2.4-py3-none-any.whl.metadata (1.1 kB)\nRequirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\nCollecting ollama\n  Downloading ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.50)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.23)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nCollecting langchain-core<1.0.0,>=0.3.49 (from langchain)\n  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\nCollecting langchain\n  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.18)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nCollecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\nCollecting chromadb>=1.0.9 (from langchain-chroma)\n  Downloading chromadb-1.0.13-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\nRequirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.11/dist-packages (from ollama) (0.28.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\nCollecting build>=1.0.3 (from chromadb>=1.0.9->langchain-chroma)\n  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\nCollecting pybase64>=1.4.1 (from chromadb>=1.0.9->langchain-chroma)\n  Downloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\nCollecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma)\n  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting posthog>=2.4.0 (from chromadb>=1.0.9->langchain-chroma)\n  Downloading posthog-6.0.0-py3-none-any.whl.metadata (6.0 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.13.2)\nCollecting onnxruntime>=1.14.1 (from chromadb>=1.0.9->langchain-chroma)\n  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.31.1)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=1.0.9->langchain-chroma)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.31.1)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.21.1)\nCollecting pypika>=0.48.9 (from chromadb>=1.0.9->langchain-chroma)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.67.1)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (1.72.0rc1)\nCollecting bcrypt>=4.0.1 (from chromadb>=1.0.9->langchain-chroma)\n  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (0.15.2)\nCollecting kubernetes>=28.1.0 (from chromadb>=1.0.9->langchain-chroma)\n  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\nCollecting mmh3>=4.0.1 (from chromadb>=1.0.9->langchain-chroma)\n  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (3.10.16)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (14.0.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb>=1.0.9->langchain-chroma) (4.23.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->ollama) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.14.0)\nCollecting langsmith>=0.1.125 (from langchain-community)\n  Downloading langsmith-0.4.4-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\nCollecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.49->langchain)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nCollecting pyproject_hooks (from build>=1.0.3->chromadb>=1.0.9->langchain-chroma)\n  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb>=1.0.9->langchain-chroma) (0.24.0)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (1.17.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.40.1)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (1.8.0)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (2.0.0)\nRequirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (3.2.2)\nCollecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma)\n  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (25.2.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (3.20.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (1.13.1)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.2.18)\nCollecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma)\n  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.70.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\nCollecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.9->langchain-chroma)\n  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb>=1.0.9->langchain-chroma)\n  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\nCollecting protobuf (from onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma)\n  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nCollecting opentelemetry-api>=1.2.0 (from chromadb>=1.0.9->langchain-chroma)\n  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.9->langchain-chroma)\n  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (8.7.0)\nCollecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb>=1.0.9->langchain-chroma)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb>=1.0.9->langchain-chroma) (1.9.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (2.19.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (0.31.1)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb>=1.0.9->langchain-chroma) (1.5.4)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma)\n  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma)\n  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma)\n  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.9->langchain-chroma) (15.0.1)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain-community) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (4.9.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (2025.3.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.9->langchain-chroma) (1.1.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (3.21.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.9->langchain-chroma) (0.1.2)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.9->langchain-chroma) (1.3.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.9->langchain-chroma) (0.6.1)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb>=1.0.9->langchain-chroma) (1.17.2)\nDownloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_chroma-0.2.4-py3-none-any.whl (11 kB)\nDownloading ollama-0.5.1-py3-none-any.whl (13 kB)\nDownloading chromadb-1.0.13-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\nDownloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.9/438.9 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\nDownloading langsmith-0.4.4-py3-none-any.whl (367 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.7/367.7 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\nDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-6.0.0-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nDownloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\nDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=22dcfba7bc36c239d1ac58f3080f02db8b53696412972d8a9453fc0131364d28\n  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\nSuccessfully built pypika\nInstalling collected packages: pypika, durationpy, uvloop, uvicorn, python-dotenv, pyproject_hooks, pybase64, protobuf, packaging, mmh3, humanfriendly, httpx-sse, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, build, pydantic-settings, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, ollama, langsmith, kubernetes, opentelemetry-sdk, langchain-core, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain, onnxruntime, chromadb, langchain-community, langchain-chroma\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.31.1\n    Uninstalling opentelemetry-api-1.31.1:\n      Successfully uninstalled opentelemetry-api-1.31.1\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.52b1\n    Uninstalling opentelemetry-semantic-conventions-0.52b1:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.52b1\n  Attempting uninstall: langsmith\n    Found existing installation: langsmith 0.3.23\n    Uninstalling langsmith-0.3.23:\n      Successfully uninstalled langsmith-0.3.23\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.31.1\n    Uninstalling opentelemetry-sdk-1.31.1:\n      Successfully uninstalled opentelemetry-sdk-1.31.1\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.50\n    Uninstalling langchain-core-0.3.50:\n      Successfully uninstalled langchain-core-0.3.50\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.7\n    Uninstalling langchain-text-splitters-0.3.7:\n      Successfully uninstalled langchain-text-splitters-0.3.7\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.22\n    Uninstalling langchain-0.3.22:\n      Successfully uninstalled langchain-0.3.22\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngoogle-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-bigtable 2.30.0 requires google-api-core[grpc]<3.0.0,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 chromadb-1.0.13 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 httpx-sse-0.4.1 humanfriendly-10.0 kubernetes-33.1.0 langchain-0.3.26 langchain-chroma-0.2.4 langchain-community-0.3.26 langchain-core-0.3.66 langchain-text-splitters-0.3.8 langsmith-0.4.4 mmh3-5.1.0 ollama-0.5.1 onnxruntime-1.22.0 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 packaging-24.2 posthog-6.0.0 protobuf-5.29.5 pybase64-1.4.1 pydantic-settings-2.10.1 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.1.1 uvicorn-0.35.0 uvloop-0.21.0 watchfiles-1.1.0\nSun Jun 29 13:28:43 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   47C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   48C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cell 2: Set up Ollama with a robust readiness check\n\nimport subprocess\nimport time\nimport os\nimport requests # We need this to check the connection\n\n# --- Step 1: Install Ollama ---\nprint(\"Installing Ollama...\")\n# Using a timeout for the curl command to avoid hanging\nprocess = subprocess.run([\"curl\", \"-fsSL\", \"https://ollama.com/install.sh\"], capture_output=True, text=True, timeout=30)\nif process.returncode != 0:\n    print(\"Error installing Ollama:\")\n    print(process.stderr)\nelse:\n    subprocess.run(process.stdout.splitlines(), shell=True, check=True)\n\n# --- Step 2: Start the Ollama server as a background process ---\nprint(\"\\nStarting Ollama server in the background...\")\n# Use subprocess.Popen for a non-blocking start\n# We redirect stdout/stderr to files so we can check them later if needed\nwith open(\"ollama_server.log\", \"w\") as log_file:\n    server_process = subprocess.Popen(\n        [\"ollama\", \"serve\"],\n        stdout=log_file,\n        stderr=subprocess.STDOUT\n    )\n\n# --- Step 3: Wait for the server to be ready ---\nprint(\"Waiting for Ollama server to become ready...\")\nmax_retries = 20\nretry_delay_seconds = 3\n\nfor i in range(max_retries):\n    try:\n        # Check if the server is up and running by making a simple request\n        response = requests.get(\"http://localhost:11434\", timeout=5)\n        if response.status_code == 200:\n            print(\"Ollama server is ready!\")\n            break\n    except requests.exceptions.ConnectionError:\n        print(f\"Attempt {i+1}/{max_retries}: Connection refused. Retrying in {retry_delay_seconds} seconds...\")\n        time.sleep(retry_delay_seconds)\nelse:\n    # This block executes if the loop completes without a 'break'\n    print(\"Error: Could not connect to Ollama server after multiple retries.\")\n    print(\"Please check the server logs in 'ollama_server.log' for more details.\")\n    # Terminate the server process to clean up\n    server_process.terminate()\n    raise ConnectionError(\"Ollama server failed to start.\")\n\n# --- Step 4: Pull the DeepSeek-R1 model ---\nprint(\"\\nOllama server is running. Now pulling the DeepSeek-R1 model...\")\n!ollama pull deepseek-r1:1.5b\n\n# Check if the model is installed\nprint(\"\\nVerifying installed models:\")\n!ollama list\n\nprint(\"\\nCell 2 execution complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T14:46:08.653131Z","iopub.execute_input":"2025-06-29T14:46:08.653425Z","iopub.status.idle":"2025-06-29T14:46:12.392421Z","shell.execute_reply.started":"2025-06-29T14:46:08.653403Z","shell.execute_reply":"2025-06-29T14:46:12.391620Z"}},"outputs":[{"name":"stdout","text":"Installing Ollama...\n\nStarting Ollama server in the background...\nWaiting for Ollama server to become ready...\nAttempt 1/20: Connection refused. Retrying in 3 seconds...\nOllama server is ready!\n\nOllama server is running. Now pulling the DeepSeek-R1 model...\n\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\npulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\npulling c5ad996bda6e: 100% ▕██████████████████▏  556 B                         \u001b[K\npulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\npulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\npulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\nverifying sha256 digest \u001b[K\nwriting manifest \u001b[K\nsuccess \u001b[K\u001b[?25h\u001b[?2026l\n\nVerifying installed models:\nNAME                ID              SIZE      MODIFIED               \ndeepseek-r1:1.5b    e0979632db5a    1.1 GB    Less than a second ago    \n\nCell 2 execution complete.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Cell 3: Load and Parse the PDF (Local File Version)\n\nfrom langchain_community.document_loaders import PyPDFLoader\nimport os\n\ndef load_and_parse_pdf_simple(file_path):\n    \"\"\"\n    Loads a PDF from a local file using PyPDFLoader and splits it by page.\n    \"\"\"\n    if not os.path.exists(file_path):\n        # This check is crucial to ensure the file is in the right place.\n        print(f\"Error: File not found at {file_path}. Please check the filename and path in the Kaggle file browser.\")\n        return []\n        \n    print(f\"Loading and parsing local PDF with PyPDFLoader at: {file_path}...\")\n    loader = PyPDFLoader(file_path) # Using PyPDFLoader\n    \n    # load_and_split() returns a list of documents, one for each page.\n    documents = loader.load_and_split()\n    print(f\"Parsed {len(documents)} pages from the PDF.\")\n    \n    return documents\n\n# --- Main execution for this cell ---\n# IMPORTANT: Update this variable with the exact path to your uploaded PDF.\n# Example: \"/kaggle/working/data/your_uploaded_filename.pdf\"\npdf_path = \"/kaggle/input/apple10-k/appleee.pdf\"\n\n# Call the function to parse the local file.\nparsed_documents = load_and_parse_pdf_simple(pdf_path)\n\n# Print the first few parsed elements to inspect the output\nif parsed_documents:\n    print(\"\\n--- Inspecting the first 5 parsed pages ---\")\n    for i, doc in enumerate(parsed_documents[:5]):\n        print(f\"--- Document Page {i+1} ---\")\n        print(f\"Text: {doc.page_content[:200]}...\") # Print first 200 chars\n        print(f\"Source: {doc.metadata.get('source')} (Page: {doc.metadata.get('page')})\")\n        print(\"-\" * 20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T14:46:20.478238Z","iopub.execute_input":"2025-06-29T14:46:20.478509Z","iopub.status.idle":"2025-06-29T14:46:25.617163Z","shell.execute_reply.started":"2025-06-29T14:46:20.478484Z","shell.execute_reply":"2025-06-29T14:46:25.616475Z"}},"outputs":[{"name":"stdout","text":"Loading and parsing local PDF with PyPDFLoader at: /kaggle/input/apple10-k/appleee.pdf...\nParsed 168 pages from the PDF.\n\n--- Inspecting the first 5 parsed pages ---\n--- Document Page 1 ---\nText: UNITED STATES\nSECURITIES AND EXCHANGE COMMISSION\nWashington, D.C. 20549\nFORM 10-K\n(Mark One)\n☒    ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nFor the fiscal ye...\nSource: /kaggle/input/apple10-k/appleee.pdf (Page: 0)\n--------------------\n--- Document Page 2 ---\nText: Indicate by check mark whether the Registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act \nof 1934 during the preceding 12 months (or for such ...\nSource: /kaggle/input/apple10-k/appleee.pdf (Page: 1)\n--------------------\n--- Document Page 3 ---\nText: Apple Inc.\nForm 10-K\nFor the Fiscal Year Ended September 28, 2024\nTABLE OF CONTENTS\nPage\nPart I\nItem 1. Business 1\nItem 1A. Risk Factors 5\nItem 1B. Unresolved Staff Comments 17\nItem 1C. Cybersecurity ...\nSource: /kaggle/input/apple10-k/appleee.pdf (Page: 2)\n--------------------\n--- Document Page 4 ---\nText: This Annual Report on Form 10-K (“Form 10-K”) contains forward-looking statements, within the meaning of the Private \nSecurities Litigation Reform Act of 1995, that involve risks and uncertainties. Ma...\nSource: /kaggle/input/apple10-k/appleee.pdf (Page: 3)\n--------------------\n--- Document Page 5 ---\nText: Services\nAdvertising\nThe Company’s advertising services include third-party licensing arrangements and the Company’s own advertising platforms.\nAppleCare\nThe Company offers a portfolio of fee-based se...\nSource: /kaggle/input/apple10-k/appleee.pdf (Page: 4)\n--------------------\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Cell 4: Smart Chunking and Metadata (Organizing the Library Shelves)\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.docstore.document import Document\n\ndef create_chunks_with_metadata(documents, company_name, report_type):\n    \"\"\"\n    Creates chunks from the documents with useful metadata.\n    \"\"\"\n    print(\"Creating chunks with metadata...\")\n    chunks = []\n    \n    # Recursive splitter for all text blocks\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1024,\n        chunk_overlap=200,\n        separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\"]\n    )\n    \n    for doc in documents:\n        # Add custom metadata for better retrieval\n        metadata = {\n            \"source\": doc.metadata.get('source'),\n            \"page\": doc.metadata.get('page'),\n            \"company\": company_name, \n            \"report_type\": report_type\n        }\n        \n        # Split the page content into smaller chunks\n        split_texts = text_splitter.split_text(doc.page_content)\n        for split_text in split_texts:\n            chunks.append(\n                Document(page_content=split_text, metadata=metadata)\n            )\n    \n    print(f\"Created {len(chunks)} chunks from the document.\")\n    return chunks\n\n# --- Main execution for this cell ---\n# Use the parsed documents from the previous cell\ncompany_name = \"Apple Inc.\"\nreport_type = \"10-K Annual Report\"\nchunks = create_chunks_with_metadata(parsed_documents, company_name, report_type)\n\n# Print a sample chunk to inspect the output\nif chunks:\n    print(\"\\n--- Example of a chunk ---\")\n    print(\"Text:\", chunks[0].page_content[:200] + \"...\")\n    print(\"Metadata:\", chunks[0].metadata)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T14:46:37.540674Z","iopub.execute_input":"2025-06-29T14:46:37.541228Z","iopub.status.idle":"2025-06-29T14:46:37.558282Z","shell.execute_reply.started":"2025-06-29T14:46:37.541193Z","shell.execute_reply":"2025-06-29T14:46:37.557519Z"}},"outputs":[{"name":"stdout","text":"Creating chunks with metadata...\nCreated 555 chunks from the document.\n\n--- Example of a chunk ---\nText: UNITED STATES\nSECURITIES AND EXCHANGE COMMISSION\nWashington, D.C. 20549\nFORM 10-K\n(Mark One)\n☒    ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nFor the fiscal ye...\nMetadata: {'source': '/kaggle/input/apple10-k/appleee.pdf', 'page': 0, 'company': 'Apple Inc.', 'report_type': '10-K Annual Report'}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Cell 5: Embedding and Vector Store (Creating the Index) with a Progress Bar\n\nfrom langchain_community.embeddings import OllamaEmbeddings\nfrom langchain_community.vectorstores import Chroma\nfrom tqdm.autonotebook import tqdm # Import tqdm for the progress bar\n\nCHROMA_DB_PATH = \"./chroma_db_finance\"\nOLLAMA_MODEL = \"deepseek-r1:1.5b\" # Use the model we pulled\n\ndef create_and_persist_vector_store(chunks):\n    \"\"\"\n    Embeds chunks and stores them in a persistent ChromaDB with a progress bar.\n    \"\"\"\n    print(f\"Initializing embedding model: {OLLAMA_MODEL}\")\n    embeddings = OllamaEmbeddings(model=OLLAMA_MODEL)\n    \n    # Create the vector store and persist it to disk\n    print(f\"Creating and persisting vector store to {CHROMA_DB_PATH}...\")\n    \n    # --- Progress Bar Added Here ---\n    # We use tqdm to wrap the list of chunks, which will show a progress bar\n    # as each chunk is processed by the embedding model.\n    # Note: This step is done implicitly by Chroma.from_documents. A direct\n    # loop with a progress bar is more visible for debugging.\n    \n    # A more visible way to track progress:\n    # This might take a while, but it will show you it's working.\n    print(f\"Processing {len(chunks)} chunks. This will take some time...\")\n    \n    vector_store = Chroma.from_documents(\n        # wrap chunks in tqdm to see progress\n        documents=tqdm(chunks, desc=\"Embedding Chunks\"),\n        embedding=embeddings,\n        persist_directory=CHROMA_DB_PATH\n    )\n    \n    print(\"Vector store created successfully!\")\n    return vector_store\n\n# --- Main execution for this cell ---\n# This part will be run only once to create the database.\nvector_store = create_and_persist_vector_store(chunks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T14:46:42.477903Z","iopub.execute_input":"2025-06-29T14:46:42.478180Z","iopub.status.idle":"2025-06-29T14:47:41.555529Z","shell.execute_reply.started":"2025-06-29T14:46:42.478159Z","shell.execute_reply":"2025-06-29T14:47:41.554836Z"}},"outputs":[{"name":"stdout","text":"Initializing embedding model: deepseek-r1:1.5b\nCreating and persisting vector store to ./chroma_db_finance...\nProcessing 555 chunks. This will take some time...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Embedding Chunks:   0%|          | 0/555 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"464604bf5bc74294b18e71211aac7e8c"}},"metadata":{}},{"name":"stdout","text":"Vector store created successfully!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Cell 6: Building the RAG Chain and Interactive Chatbot Querying (Direct Output Version)\n\nfrom langchain_community.llms import Ollama\nfrom langchain.chains import RetrievalQA\nfrom langchain.prompts import PromptTemplate\n\ndef build_rag_chain(vector_store):\n    \"\"\"\n    Builds the Retrieval-Augmented Generation chain.\n    \"\"\"\n    print(\"Building RAG chain...\")\n    \n    llm = Ollama(model=\"deepseek-r1:1.5b\", temperature=0) \n    retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n    \n    # --- PROMPT MODIFICATION FOR DIRECT OUTPUT ---\n    # We are changing the prompt to tell the LLM to be very concise and direct.\n    template = \"\"\"\n    You are a very concise financial chatbot. Answer the question **as briefly and directly as possible** based **only** on the provided document excerpts.\n    **Do not include any preambles, intros, or sections like 'Analysis' or 'Conclusion'. Just provide the final answer as a single sentence or a brief paragraph.**\n    If the information is not explicitly mentioned in the context, state that you cannot find the information in the document.\n\n    Context:\n    {context}\n    \n    Question: {question}\n    \n    Answer:\n    \"\"\"\n    \n    prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n    \n    rag_chain = RetrievalQA.from_chain_type(\n        llm=llm,\n        chain_type=\"stuff\",\n        retriever=retriever,\n        return_source_documents=True, # We still return sources for verification\n        chain_type_kwargs={\"prompt\": prompt}\n    )\n    \n    print(\"RAG chain built successfully.\")\n    return rag_chain\n\ndef query_rag_system(rag_chain, query):\n    \"\"\"\n    Queries the RAG system and prints only the concise answer.\n    \"\"\"\n    print(f\"\\n--- Processing Query: '{query}' ---\")\n    response = rag_chain.invoke({\"query\": query})\n    \n    # --- OUTPUT MODIFICATION ---\n    # We now only print the result, without the extra headers or sources.\n    # The 'return_source_documents' is still True in the chain for a proper RAG lookup.\n    print(response['result'])\n    \n    return response\n\n# --- Main execution for this cell ---\nrag_chain = build_rag_chain(vector_store)\n\nprint(\"\\n--- Interactive Chatbot Mode ---\")\nprint(\"Enter your question about the financial document.\")\nprint(\"Type 'exit' to quit the chatbot.\")\n\nwhile True:\n    user_query = input(\"\\nYour question: \")\n    \n    if user_query.lower() == 'exit':\n        print(\"Exiting chatbot. Goodbye!\")\n        break\n        \n    query_rag_system(rag_chain, user_query)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T15:08:19.180150Z","iopub.execute_input":"2025-06-29T15:08:19.180931Z","iopub.status.idle":"2025-06-29T15:19:52.207756Z","shell.execute_reply.started":"2025-06-29T15:08:19.180907Z","shell.execute_reply":"2025-06-29T15:19:52.207023Z"}},"outputs":[{"name":"stdout","text":"Building RAG chain...\nRAG chain built successfully.\n\n--- Interactive Chatbot Mode ---\nEnter your question about the financial document.\nType 'exit' to quit the chatbot.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nYour question:  should i buy this stock ?\n"},{"name":"stdout","text":"\n--- Processing Query: 'should i buy this stock ?' ---\n<think>\nOkay, so I need to figure out whether someone should buy a stock based on the provided context. Let me go through the information step by step.\n\nFirst, looking at the Annual Report on Form 10-K, it's a financial document that includes forward-looking statements and management discussions. The context mentions several sections like \"Business\" and \"Management’s Discussion and Analysis.\" These sections often discuss future risks and uncertainties, which can indicate potential risks associated with investing in a stock.\n\nThe question is whether someone should buy the stock. To answer this, I need to see if there's any explicit information in the provided excerpt that suggests the stock is undervalued or has positive fundamentals.\n\nLooking through the context, I don't see any direct statements about the company's financial health, profitability, or specific risks associated with the stock. The focus seems more on broader market trends and regulatory developments rather than individual stock performance.\n\nThe section about disclosure controls and procedures mentions that they ensure material information is disclosed to the investor by others within the entity during the period of preparation. This could be relevant if there are concerns about insider trading, but it's not directly related to whether to buy the stock.\n\nThere's also a part discussing internal control over financial reporting, which again doesn't address individual stocks or their valuation.\n\nThe series section lists several items under \"Series 25,\" which might relate to specific types of securities, but without more context on the company or its stock performance, this isn't helpful for determining if buying is advisable.\n\nThe bankruptcy law section talks about procedures for filing a petition for bankruptcy or relief, which could be relevant in cases where the company's assets are insufficient, but again, not directly related to individual stock valuation.\n\nLastly, the notes issued in book-entry form and their registration details don't provide any information on the value of specific stocks unless there's implied information about their performance based on market trends, which isn't present here.\n\nSince none of these sections mention anything about the stock's fundamentals, profitability, or any other factors that would suggest it's a good investment, I can conclude that the provided context doesn't indicate whether to buy this stock.\n</think>\n\nThe provided context does not contain explicit information about the stock's fundamentals, profitability, or valuation. It focuses on broader market trends and regulatory developments rather than individual stock performance. Therefore, there is no indication to recommend buying the stock based on the given excerpt.\n\nAnswer: No, there is no explicit information in the provided context suggesting that this stock should be purchased.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nYour question:  exit \n"},{"name":"stdout","text":"\n--- Processing Query: 'exit ' ---\n<think>\nOkay, so I need to figure out the answer to this question about the financial chatbot's response based on the provided document excerpts. The user has given me a lot of context, including various sections like periods up to 150 days, intellectual property issues, specific notes with interest rates and maturities, and some trading plans involving insider trading arrangements.\n\nThe question is \"exit.\" I'm not entirely sure what that refers to in the financial context. It could mean exiting a deal, exiting debt, or perhaps something else like exiting a company's operations. Looking through the document, I see mentions of notes with specific maturities and interest rates, which might relate to debt or investment returns.\n\nI notice there are sections about 3.050% 2029 Notes and 2031 Notes, both with semi-annual and annual interest payments respectively. The 3.050% notes have a maturity in 2029, which is a few years away. Maybe the \"exit\" here refers to exiting a debt or a note issue.\n\nAlso, there's an inside trading arrangement involving Deirdre O’Brien for shares, vesting over two years. That could be related to exiting a position if someone wants to sell their shares early. The plan includes equity awards and excludes withholding taxes, which might tie into exiting a company by selling stock.\n\nThe State Aid Decision about Ireland's tax changes is another point of interest. It mentions reducing recovery amounts for taxes paid elsewhere, which could relate to exiting or managing debt obligations in different countries.\n\nPutting this together, the most likely answer is that the Company is considering exiting a debt issue, perhaps the 3.050% 2029 Notes, given their maturity date and interest structure. The trading plan involving insider trading might indicate strategic decisions about stock sales or investments outside the current debt.\n\nI should make sure I'm not missing any other possible meanings of \"exit\" in this context. Maybe it's related to exiting a company entirely, but the document doesn't mention that much. It seems more likely tied to specific financial instruments and strategies within the provided excerpts.\n</think>\n\nThe Company is considering exiting a debt issue, specifically the 3.050% 2029 Notes, which have a maturity in 2029. This decision could be related to strategic stock sales or managing debt obligations outside the current company.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nYour question:  exit\n"},{"name":"stdout","text":"Exiting chatbot. Goodbye!\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# List the files in Ollama's model storage directory\n!ls -lh /root/.ollama/models/blobs/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T15:28:29.533977Z","iopub.execute_input":"2025-06-29T15:28:29.534291Z","iopub.status.idle":"2025-06-29T15:28:29.666269Z","shell.execute_reply.started":"2025-06-29T15:28:29.534268Z","shell.execute_reply":"2025-06-29T15:28:29.665344Z"}},"outputs":[{"name":"stdout","text":"total 1.1G\n-rw-r--r-- 1 root root 1.1K Jun 29 13:30 sha256-6e4c38e1172f42fdbff13edf9a7a017679fb82b0fde415a3e8b3c31c6ed4a4e4\n-rw-r--r-- 1 root root  487 Jun 29 13:30 sha256-a85fe2a2e58e2426116d3686dfdc1a6ea58640c1e684069976aa730be6c1fa01\n-rw-r--r-- 1 root root 1.1G Jun 29 13:30 sha256-aabd4debf0c8f08881923f2c25fc0fdeed24435271c2b3e92c4af36704040dbc\n-rw-r--r-- 1 root root  556 Jun 29 13:30 sha256-c5ad996bda6eed4df6e3b605a9869647624851ac248209d22fd5e2c0cc1121d3\n-rw-r--r-- 1 root root  148 Jun 29 13:30 sha256-f4d24e9138dd4603380add165d2b0d970bef471fac194b436ebd50e6147c6588\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Copy the model file to the working directory\n!cp /root/.ollama/models/blobs/sha256-f4d24e9138dd4603380add165d2b0d970bef471fac194b4.bin /kaggle/working/deepseek-r1-1.5b.bin","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T15:31:09.197856Z","iopub.execute_input":"2025-06-29T15:31:09.198123Z","iopub.status.idle":"2025-06-29T15:31:09.322397Z","shell.execute_reply.started":"2025-06-29T15:31:09.198099Z","shell.execute_reply":"2025-06-29T15:31:09.321689Z"}},"outputs":[{"name":"stdout","text":"cp: cannot stat '/root/.ollama/models/blobs/sha256-f4d24e9138dd4603380add165d2b0d970bef471fac194b4.bin': No such file or directory\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}